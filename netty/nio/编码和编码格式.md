# 编码和编码格式
## 例子
```
public class CharsetTest01 {

    public static void main(String[] args) throws Exception {
        //读入的文件
        String inputFile="Charset01";
        //写出的文件
        String outputFile="Charset02";
        
        RandomAccessFile inputRandomAccessFile = new RandomAccessFile(inputFile, "r");
        RandomAccessFile outputRandomAccessFile = new RandomAccessFile(outputFile, "rw");

        long inputLength=new File(inputFile).length();
        
        //获取读和写的通道 
        FileChannel inputFileChannel = inputRandomAccessFile.getChannel();
        FileChannel outputFileChannel = outputRandomAccessFile.getChannel();
        //在内存中对文件进行操作
        MappedByteBuffer inputData=inputFileChannel.map(FileChannel.MapMode.READ_ONLY,0,inputLength);
        //原本的文件是utf-8
        Charset charset=Charset.forName("iso-8859-1");
        CharsetDecoder decoder=charset.newDecoder();
        CharsetEncoder encoder=charset.newEncoder();
        //inputData是字节类型的,我们对它进行编码通过iso-8859-1  
        CharBuffer charBuffer=decoder.decode(inputData);
        //然后通过iso-8859-1的表示进行解码,字符成字节
        ByteBuffer outputData=encoder.encode(charBuffer);
        //写 
        outputFileChannel.write(outputData);
        
        //关闭资源
        inputRandomAccessFile.close();
        outputRandomAccessFile.close();
    }
}
```
这样的话,中文也不会出现乱码
## 编码和编码格式
编码在我们日常开发过程中经常有遇到，常见的编码格式有ASCII、ISO-8859-1、GB2312、GBK、GB18030、UNICODE、UTF-8、UTF-16等，其中GB2312、GBK、GB18030、UTF-8、UTF-16都可以用来表示中文，那么哪种存储中文会比较合适呢，下面会对这几种编码一一介绍便会有结论。

我们知道计算机中最小的存储单位是字节（byte），一个字节所能表示的字符数又有限，1byte=8bit，一个字节最多也只能表示255个字符，而世界上的语种又多，都有各种不同的字符，无法用一个byte表示，所以java中的char表示字符就是来解决这种编码问题的，一个char占两个字节，所以从char到最小单位byte之间必须经过编码。
**ASCII**
ASCII码用7位表示，只能表示128个字符
**ISO-8859-1**
既然ASCII只能表示128个字符，显示是不能完全表示完的，所以ISO-8859-1扩展了ASCII编码，在ASCII编码之上又增加了西欧语言、希腊语、泰语、阿拉伯语、希伯来语对应的文字符号，它是向下兼容ASCII编码的。
**ISO-8859-1也是单字节编码，但它是一个8位的容器，它能表示256个字符。**

**GB2312**
全称为信息交换用汉字编码字符集，是中国于1980年发布，主要用于计算机系统中的汉字处理
GB2312覆盖了汉字的大部分使用率，但不能处理像古汉语等特殊的罕用字，所以后来出现了像GBK、GB18030这种编码。
**GBK**
**GB18030**

UNICODE
为了自己的语言能在计算机中正常显示，每个国家和地区都有各自的编码，所以编码多了谁也不认识对方的编码，这时候ISO组织就提出了一种新的编码叫UNICODE编码让全球的文化、字符、符号都能支持。**UNICODE在制定时计算机容量已不是问题，所以设计成了固定两个字节，所有的字符都用16位表示**，包括之前只占8位的英文字符等，所以会造成空间的浪费，UNICODE在很长的一段时间内都没有得到推广应用。

UTF-16
UTF-16是UNICODE的具体实现，16即16位，UTF-16即是这个来由，定义了UNICODE字符在计算机中的存储方式，UTF-16同样使用了两个字节来表示任何字符，这样使得操作字符串非常高效，这也是java把UTF-16作为字符在内存中存储的格式的重要原因。
UTF-16适合在磁盘与内存之间使用，字符和字节的相互转换会更加简单和高效，但不适合在网络上传输，因为网络传输可能会损坏字节流。


UTF-8
虽然UTF-16很高效，但也是UNICODE最大的坏处，使得所有单字节字符一定要占两个字节，存储空间放大了一倍，这明显消耗了资源，不符合现在互联网高速发展的现状。所以有了UTF-8，它是UNICODE的一种可变长度字符编码的实现，它可以使用1～6个定长字节来编码UNICODE字符。


UTF-8对ASCII字符使用单字节存储，单个字符损坏也不会影响后面的字符，所以UTF-8非常适合在网络上面传统，也是现在使用最广泛的编码之一。


如果要表示中文，UTF-8编码效率要大于GBK，小于UTF-16，所以它也是除了GBK之外最理想的编码方式。

编码在我们日常开发过程中经常有遇到，常见的编码格式有ASCII、ISO-8859-1、GB2312、GBK、GB18030、UNICODE、UTF-8、UTF-16等，其中GB2312、GBK、GB18030、UTF-8、UTF-16都可以用来表示中文，那么哪种存储中文会比较合适呢，下面会对这几种编码一一介绍便会有结论。

## 为什么例子中不会出现乱码
我们找出核心的句子
```
        Charset charset=Charset.forName("iso-8859-1");
        CharsetDecoder decoder=charset.newDecoder();
        CharsetEncoder encoder=charset.newEncoder();
        //inputData是字节类型的,我们对它进行编码通过iso-8859-1  
        CharBuffer charBuffer=decoder.decode(inputData);
        //然后通过iso-8859-1的表示进行解码,字符成字节
        ByteBuffer outputData=encoder.encode(charBuffer);
```
现在我们有utf-8的"你好",每一个汉字在utf-8中是三个字节
```
   你         好
AB CD EF   GH IM RR 

```
但是iso-8859-1对AB CD EF   GH IM RR进行编码,就把这6个字节各变成一个汉字,这个时候是乱码的,
但是我们又通过iso-8859-1的方式进行解码,这个时候得到的字节还是AB CD EF   GH IM RR,所以通过utf-8的方式显示,还是不会出现问题